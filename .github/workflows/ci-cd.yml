 name: Python CI/CD Pipeline

 on:
   push:
     branches:
       - main
   pull_request:
     branches:
       - main
   schedule: # Desencadenar en un horario programado
-    # Ejecuta el scraper una vez al día, por ejemplo, a las 00:00 UTC
-    # Usa crontab.guru para ajustar el horario (ej. '0 0 * * *' es medianoche UTC)
-    - cron: '0 0 * * *'
+    # Ejecuta el scraper una vez al día a las 20:50 UTC (que es 15:50 en Ecuador)
+    - cron: '50 20 * * *' # <--- ¡CAMBIA ESTA LÍNEA!
   workflow_dispatch: # Permite ejecutar manualmente si lo deseas

 jobs:
   build-and-test:
     runs-on: ubuntu-latest

     steps:
       - name: Checkout repository
         uses: actions/checkout@v4

       - name: Set up Python 3.10
         uses: actions/setup-python@v5
         with:
           python-version: '3.10'
           cache: 'pip'

       - name: Install dependencies
         run: |
           python -m pip install --upgrade pip
           pip install -r requirements.txt
           pip install flake8 pytest pandas

       - name: Check code style with Flake8
         run: |
           flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
           flake8 . --count --exit-zero --max-complexity=10 --max-line-length=120 --statistics

       - name: Run unit and integration tests
         run: |
           echo "Ejecutando pruebas unitarias/integración si existen..."
           pytest || true

       - name: Smoke test main.py (Help command)
         run: |
           echo "Ejecutando 'python main.py --help' para verificar la invocación del script..."
           python main.py --help

   analyze-and-deploy-trends:
     needs: build-and-test
     if: github.ref == 'refs/heads/main' && github.event_name == 'push'
     runs-on: ubuntu-latest

     env:
       SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
       SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
       GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}

     steps:
       - name: Checkout repository
         uses: actions/checkout@v4

       - name: Set up Python 3.10
         uses: actions/setup-python@v5
         with:
           python-version: '3.10'
           cache: 'pip'

       - name: Install dependencies
         run: |
           python -m pip install --upgrade pip
           pip install -r requirements.txt

       - name: Run Trend Analysis and store in Supabase
         run: |
           echo "Ejecutando análisis de tendencias y almacenando en Supabase..."
           python main.py --analyze-trends --analysis-date $(date +'%Y-%m-%d')
           echo "Análisis de tendencias completado y almacenado. Verifica Supabase."

   run-scrapers-daily:
     needs: build-and-test
     if: (github.event_name == 'schedule' || github.event_name == 'workflow_dispatch') && github.ref == 'refs/heads/main'
     runs-on: ubuntu-latest

     env:
       SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
       SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}

     steps:
       - name: Checkout repository
         uses: actions/checkout@v4

       - name: Set up Python 3.10
         uses: actions/setup-python@v5
         with:
           python-version: '3.10'
           cache: 'pip'

       - name: Install dependencies
         run: |
           python -m pip install --upgrade pip
           pip install -r requirements.txt
       - name: Execute Scrapers
         run: |
           echo "Iniciando ejecución de scrapers programada (15:50 Ecuador / 20:50 UTC)..." # Nota: He actualizado el mensaje para mayor claridad.
           python main.py --spiders linkedin,computrabajo --continent Latam --country "Todos los Países" --max_jobs 100
           echo "Ejecución de scrapers finalizada."
         timeout-minutes: 30